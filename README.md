# Unsloth ile Qwen2.5-Coder Fine-Tuning

Bu proje, **Unsloth** ve **LoRA** (Low-Rank Adaptation) kullanarak **Qwen2.5-Coder-1.5B-Instruct** modelinin fine-tuning (ince ayar) iÅŸlemini gÃ¶stermektedir. EÄŸitim sÃ¼reci, modelin kodlama yeteneklerini geliÅŸtirmek amacÄ±yla **Google Colab** Ã¼zerinde gerÃ§ekleÅŸtirilmiÅŸtir.

## ğŸš€ Proje Ã–zeti

Bu projenin amacÄ±, verimli eÄŸitim teknikleri kullanarak hafif ama gÃ¼Ã§lÃ¼ bir kodlama modelini fine-tune etmektir. Daha hÄ±zlÄ± ve bellek aÃ§Ä±sÄ±ndan verimli bir eÄŸitim iÃ§in Unsloth kÃ¼tÃ¼phanesi kullanÄ±lmÄ±ÅŸtÄ±r.

*   **Temel Model:** `Qwen/Qwen2.5-Coder-1.5B-Instruct`
*   **Teknik:** Unsloth ile LoRA (Low-Rank Adaptation)
*   **Platform:** Google Colab (T4/L4/A100 GPU Ã¶nerilir(A100 kullanÄ±ldÄ±!))

## ğŸ“‚ Veri Setleri

AÅŸaÄŸÄ±daki veri setleri kullanÄ±larak iki farklÄ± eÄŸitim stratejisi izlenmiÅŸtir:

1.  **Deep Instruction :** `Naholav/CodeGen-Deep-5K` (`DeepTrain.py` dosyasÄ±nda kullanÄ±ldÄ±)
2.  **Diverse Instruction :** `Naholav/CodeGen-Diverse-5K` (`DiverseTrain.py` dosyasÄ±nda kullanÄ±ldÄ±)

## ğŸ› ï¸ Google Colab Kurulumu

Bu proje Google Colab iÃ§in optimize edilmiÅŸtir. Kodlar, checkpoint'leri ve modelleri kaydetmek iÃ§in Google Drive'Ä± baÄŸlayacak ÅŸekilde ayarlanmÄ±ÅŸtÄ±r.

1.  Scriptleri (`DeepTrain.py` veya `DiverseTrain.py`) ya da notebook dosyasÄ±nÄ± (`eval.ipynb`) Google Colab'da aÃ§Ä±n.
2.  GPU Ã§alÄ±ÅŸma zamanÄ±nÄ±n (runtime) seÃ§ili olduÄŸundan emin olun.
3.  Kodlar, Ã§Ä±ktÄ±larÄ± `/content/drive/MyDrive/NLPlora/` dizinine kaydetmek iÃ§in Google Drive'Ä±nÄ±zÄ± otomatik olarak baÄŸlayacaktÄ±r.

## ğŸ“¦ Kurulum

Projeyi yerel ortamÄ±nÄ±zda Ã§alÄ±ÅŸtÄ±rmak veya ortamÄ± yeniden oluÅŸturmak isterseniz, gerekli baÄŸÄ±mlÄ±lÄ±klarÄ± yÃ¼kleyin:

```bash
pip install -r requirements.txt
```

*Not: Unsloth, CUDA sÃ¼rÃ¼mÃ¼nÃ¼ze baÄŸlÄ± olarak Ã¶zel kurulum adÄ±mlarÄ± gerektirebilir. Detaylar iÃ§in [Unsloth dokÃ¼mantasyonuna](https://github.com/unslothai/unsloth) bakabilirsiniz.*

## ğŸ’» KullanÄ±m

### EÄŸitim (Training)
"Deep" veri seti ile modeli eÄŸitmek iÃ§in:
```python
python DeepTrain.py
```

"Diverse" veri seti ile modeli eÄŸitmek iÃ§in:
```python
python DiverseTrain.py
```

### DeÄŸerlendirme (Evaluation)
DeÄŸerlendirme iÅŸlemi `eval.ipynb` dosyasÄ± ile yapÄ±lÄ±r. Bu notebook:
1.  DeÄŸerlendirme ortamÄ±nÄ± (LiveCodeBench) kurar.
2.  Fine-tune edilmiÅŸ modelleri Google Drive'dan yÃ¼kler.
3.  AtCoder gibi platformlar Ã¼zerinde benchmark testlerini Ã§alÄ±ÅŸtÄ±rÄ±r.

## ğŸ“Š SonuÃ§lar

DetaylÄ± analizler, loss grafikleri ve benchmark karÅŸÄ±laÅŸtÄ±rmalarÄ± **[Proje Raporu (REPORT.md)](REPORT.md)** dosyasÄ±nda bulunabilir.

## ğŸ“ Dosya YapÄ±sÄ±

*   `DeepTrain.py`: Deep veri seti iÃ§in eÄŸitim scripti.
*   `DiverseTrain.py`: Diverse veri seti iÃ§in eÄŸitim scripti.
*   `eval.ipynb`: Modelleri deÄŸerlendirmek iÃ§in Jupyter notebook.
*   `REPORT.md`: EÄŸitim sonuÃ§larÄ±nÄ±n ve analizlerin yer aldÄ±ÄŸÄ± detaylÄ± rapor.
*   `requirements.txt`: Python baÄŸÄ±mlÄ±lÄ±k listesi.
*   `Rapor/`: Raporda kullanÄ±lan gÃ¶rselleri ve grafikleri iÃ§eren klasÃ¶r.

---
*Bu proje, bir Fine-Tuning Ã¶devi kapsamÄ±nda hazÄ±rlanmÄ±ÅŸtÄ±r.*
